{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8ec87f",
   "metadata": {},
   "source": [
    "Esta notebook contiene bloques de código útiles para el juego TacTix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tactix_env import TacTixEnv\n",
    "from trainer_agent import TrainerAgent\n",
    "from random_agent import RandomTacTixAgent\n",
    "from minimax_agent import MinimaxAgent\n",
    "import wandb\n",
    "from expectimax_agent import ExpectimaxAgent\n",
    "from play import play_vs_other_agent, run_multiple_games, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TacTixEnv(board_size=6, misere=False)\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Example action: take from row 1, positions 0 to 2\n",
    "obs, reward, done, _ = env.step([1, 0, 2, 1])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116d4b1",
   "metadata": {},
   "source": [
    "Random Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8699f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import minimax_agent\n",
    "import numpy as np  # Make sure numpy is imported\n",
    "importlib.reload(minimax_agent)\n",
    "from minimax_agent import MinimaxAgent\n",
    "\n",
    "random_agent_1 = RandomTacTixAgent(env)\n",
    "random_agent_2 = RandomTacTixAgent(env)\n",
    "minimax_agent = MinimaxAgent(env)\n",
    "\n",
    "play_vs_other_agent(env, random_agent_1, minimax_agent, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96a8f7",
   "metadata": {},
   "source": [
    "Multiple Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_multiple_games(env, random_agent_1, minimax_agent, num_games=10)\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f81425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import expectimax_agent\n",
    "import numpy as np\n",
    "importlib.reload(expectimax_agent)\n",
    "from expectimax_agent import ExpectimaxAgent\n",
    "\n",
    "# Crear un agente expectimax\n",
    "expectimax_agent = ExpectimaxAgent(env, depth=2)\n",
    "\n",
    "# Jugar contra un agente aleatorio\n",
    "print(\"Expectimax vs Random:\")\n",
    "play_vs_other_agent(env, expectimax_agent, random_agent_1, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba629a8",
   "metadata": {},
   "source": [
    "## Play Minimax vs Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea138b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax. Run a series of games with different difficulties for the TrainerAgent\n",
    "difficulties = [i / 10 for i in range(11)]\n",
    "results_summary_minimax = []\n",
    "\n",
    "total_agent1_wins_minimax = 0\n",
    "total_agent2_wins_minimax = 0\n",
    "total_agent2_losses_minimax = 0\n",
    "\n",
    "wandb.init(project=\"tactix-experiments\", name=\"trainer_vs_minimax\")\n",
    "\n",
    "for d in difficulties:\n",
    "    agent1 = TrainerAgent(env, difficulty=d)\n",
    "    agent2 = MinimaxAgent(env)\n",
    "    \n",
    "    results = run_multiple_games(env, agent1, agent2, num_games=20)\n",
    "    results_summary_minimax.append((d, results[\"agent1_wins\"], results[\"agent2_wins\"]))\n",
    "    \n",
    "    total_agent1_wins_minimax += results[\"agent1_wins\"]\n",
    "    total_agent2_wins_minimax += results[\"agent2_wins\"]\n",
    "    total_agent1_losses_minimax += results[\"agent2_wins\"]\n",
    "    \n",
    "    wandb.log({\n",
    "        \"difficulty\": d,\n",
    "        \"agent1_wins\": results[\"agent1_wins\"],\n",
    "        \"agent2_wins\": results[\"agent2_wins\"]\n",
    "    })\n",
    "    \n",
    "table= wandb.Table(data =[\n",
    "    [\"Agent1\", total_agent1_wins_minimax],\n",
    "    [\"Agent2\", total_agent2_wins_minimax]\n",
    "], columns=[\"Agent\", \"Wins\"])\n",
    "\n",
    "\n",
    "wandb.log({\"total_wins_bar_chat\": wandb.plot.bar(table, \"Agent\", \"Wins\", title=\"Total Wins by Agent\")})\n",
    "\n",
    "print(f\"Total Agent 2 Wins: {total_agent2_wins_minimax}\")\n",
    "print(f\"Total Agent 2 Losses: {total_agent2_losses_minimax}\")\n",
    "\n",
    "wandb.finish()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax. Plot results with double bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator  # Importar MaxNLocator para ticks de valores enteros\n",
    "\n",
    "probs = [x[0] for x in results_summary_minimax]\n",
    "agent1_wins_minimax = [x[1] for x in results_summary_minimax]\n",
    "agent2_wins_minimax = [x[2] for x in results_summary_minimax]\n",
    "\n",
    "# Set width for bars\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(probs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar1 = plt.bar(index - bar_width/2, agent1_wins_minimax, bar_width, label='Trainer Wins')\n",
    "bar2 = plt.bar(index + bar_width/2, agent2_wins_minimax, bar_width, label='Agent Minimax Wins')\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, v in enumerate(agent1_wins_minimax):\n",
    "    plt.text(i - bar_width/2, v + 1, str(v), ha='center')\n",
    "\n",
    "for i, v in enumerate(agent2_wins_minimax):\n",
    "    plt.text(i + bar_width/2, v + 1, str(v), ha='center')\n",
    "\n",
    "# Configure the chart\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Number of Wins')\n",
    "plt.title('Agent Minimax Wins vs Difficulty Comparison')\n",
    "plt.xticks(index, [f\"{p:.1f}\" for p in probs])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Configurar el eje Y para que solo muestre valores enteros\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1e5ea",
   "metadata": {},
   "source": [
    "## Play Expectimax vs trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExpectiMax. Run a series of games with different difficulties for the TrainerAgent \n",
    "difficulties = [i / 10 for i in range(11)]\n",
    "results_summary_expectimax = []\n",
    "\n",
    "total_agent1_wins_expectimax=0\n",
    "total_agent2_wins_expectimax=0\n",
    "\n",
    "wandb.init(project=\"tactix-experiments\", name=\"trainer_vs_expectiMax\")\n",
    "\n",
    "for d in difficulties:\n",
    "    agent1 = TrainerAgent(env, difficulty=d)\n",
    "    agent2 = ExpectimaxAgent(env)\n",
    "    \n",
    "    results = run_multiple_games(env, agent1, agent2, num_games=20)\n",
    "    results_summary_expectimax.append((d, results[\"agent1_wins\"], results[\"agent2_wins\"]))\n",
    "    \n",
    "    total_agent1_wins_expectimax += results[\"agent1_wins\"]\n",
    "    total_agent2_wins_expectimax += results[\"agent2_wins\"]\n",
    "    \n",
    "    wandb.log({\n",
    "        \"difficulty\": d,\n",
    "        \"agent1_wins\": results[\"agent1_wins\"],\n",
    "        \"agent2_wins\": results[\"agent2_wins\"]\n",
    "    })\n",
    "    \n",
    "table= wandb.Table(data =[\n",
    "    [\"Agent1\", total_agent1_wins_expectimax],\n",
    "    [\"Agent2\", total_agent2_wins_expectimax]\n",
    "], columns=[\"Agent\", \"Wins\"])\n",
    "\n",
    "\n",
    "wandb.log({\"total_wins_bar_chat\": wandb.plot.bar(table, \"Agent\", \"Wins\", title=\"Total Wins by Agent\")})\n",
    "\n",
    "wandb.finish()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02474123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExpectiMax. Plot results with double bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator  # Importar MaxNLocator para ticks de valores enteros\n",
    "\n",
    "probs = [x[0] for x in results_summary_expectimax]\n",
    "agent1_wins_expectimax = [x[1] for x in results_summary_expectimax]\n",
    "agent2_wins_expectimax = [x[2] for x in results_summary_expectimax]\n",
    "\n",
    "# Set width for bars\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(probs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar1 = plt.bar(index - bar_width/2, agent1_wins_expectimax, bar_width, label='Trainer Wins')\n",
    "bar2 = plt.bar(index + bar_width/2, agent2_wins_expectimax, bar_width, label='Agent Expectimax Wins')\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, v in enumerate(agent1_wins_expectimax):\n",
    "    plt.text(i - bar_width/2, v + 1, str(v), ha='center')\n",
    "\n",
    "for i, v in enumerate(agent2_wins_expectimax):\n",
    "    plt.text(i + bar_width/2, v + 1, str(v), ha='center')\n",
    "\n",
    "# Configure the chart\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Number of Wins')\n",
    "plt.title('Agent Expectimax Wins vs Difficulty Comparison')\n",
    "plt.xticks(index, [f\"{p:.1f}\" for p in probs])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Configurar el eje Y para que solo muestre valores enteros\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tactix-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
